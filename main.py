"""
Project Seeka - ä¸»å…¥å£æ–‡ä»¶
"""
import signal
import sys
from modules.memory import MemoryManager
from modules.memory.logger import get_logger
from modules.voice import VoiceManager
from modules.llm import call_llm
from modules.config import REF_AUDIO, PROMPT_TEXT, SOVITS_URL, GPT_SOVITS_PATH, MODEL_NAME, SYSTEM_PROMPT
from modules.utils import clean_text, start_gpt_sovits_api, check_sovits_service

# å…¨å±€å˜é‡ç”¨äºä¿¡å·å¤„ç†
memory_manager = None
sovits_process = None

def signal_handler(sig, frame):
    """å¤„ç† Ctrl+C ä¿¡å·ï¼Œç¡®ä¿è®°å¿†è¢«ä¿å­˜"""
    if memory_manager:
        memory_manager.summarize_day()
        memory_manager.close()
    if sovits_process:
        sovits_process.terminate()
        sovits_process.wait()
    sys.exit(0)

def main():
    global memory_manager, sovits_process

    memory_logger = get_logger()
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    
    # å¯åŠ¨ GPT-SoVITS API æœåŠ¡
    sovits_process = start_gpt_sovits_api(GPT_SOVITS_PATH)
    if sovits_process is None:
        print("è­¦å‘Š: GPT-SoVITS API æœåŠ¡å¯åŠ¨å¤±è´¥ã€‚è¯·æ£€æŸ¥ GPT_SOVITS_PATH ç¯å¢ƒå˜é‡å’Œ GPT-SoVITS å®‰è£…ã€‚")
        print("æ‚¨å¯ä»¥æ‰‹åŠ¨å¯åŠ¨ GPT-SoVITS æœåŠ¡ï¼Œæˆ–æŒ‰ Enter ç»§ç»­ï¼ˆè¯­éŸ³åŠŸèƒ½å°†ä¸å¯ç”¨ï¼‰ã€‚")
        input("æŒ‰ Enter ç»§ç»­...")
    
    # åˆå§‹åŒ–æ¨¡å—
    memory_manager = MemoryManager()
    graph_memory = GraphMemory()
    voice_manager = VoiceManager(
        sovits_url=SOVITS_URL,
        ref_audio=REF_AUDIO,
        prompt_text=PROMPT_TEXT,
    )
    
    # å¯åŠ¨æ—¶æ¸…ç†è®°å¿†ï¼ˆæ¨¡æ‹Ÿè‡ªç„¶é—å¿˜ï¼‰
    memory_manager.cleanup_old_memories()
    
    # æ˜¾ç¤ºè®°å¿†ç³»ç»ŸçŠ¶æ€
    stats = memory_manager.get_memory_stats()
    print(f"\nğŸ“Š è®°å¿†çŠ¶æ€: çŸ­æœŸ({stats['short_term']}/{stats['short_term_capacity']}) | "
          f"å·¥ä½œ({stats['working_memory']}) | é•¿æœŸ({stats['long_term']}) | æƒ…æ„Ÿ({stats['emotional']})")
    
    print("\nProject Local å·²å¯åŠ¨ã€‚è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºï¼Œè¾“å…¥ 'status' æŸ¥çœ‹è®°å¿†çŠ¶æ€ã€‚")
    
    while True:
        user_input = input("\nä½ : ")
        
        # ç‰¹æ®Šå‘½ä»¤å¤„ç†
        if user_input.lower() in ['exit', 'quit']:
            # é€€å‡ºå‰ç”Ÿæˆæ¯æ—¥æ€»ç»“å¹¶ä¿å­˜æ‰€æœ‰è®°å¿†
            memory_manager.summarize_day()
            memory_manager.close()  # ç¡®ä¿æ‰€æœ‰è®°å¿†éƒ½å·²ä¿å­˜
            break
        
        if user_input.lower() == 'status':
            stats = memory_manager.get_memory_stats()
            print(f"\nğŸ“Š è®°å¿†ç³»ç»ŸçŠ¶æ€:")
            print(f"  â”œâ”€ çŸ­æœŸè®°å¿†: {stats['short_term']}/{stats['short_term_capacity']} è½®")
            print(f"  â”œâ”€ å·¥ä½œè®°å¿†: {stats['working_memory']} æ¡")
            print(f"  â”œâ”€ é•¿æœŸè®°å¿†: {stats['long_term']} æ¡")
            print(f"  â”œâ”€ æƒ…æ„Ÿè®°å¿†: {stats['emotional']} æ¡")
            print(f"  â””â”€ å½“å‰æƒ…æ„Ÿ: {stats['current_emotion']}")
            continue
        
        # æ¸…ç†è¾“å…¥æ–‡æœ¬
        cleaned_input = clean_text(user_input)

        # è¯­ä¹‰å›¾è°±æ‘„å–ï¼ˆå¯è§£é‡Šè®°å¿†ï¼‰
        graph_memory.ingest_utterance(cleaned_input, speaker="ç”¨æˆ·", source="dialog")
        
        # æ·»åŠ åˆ°çŸ­æœŸè®°å¿†
        memory_manager.add_to_short_term("ç”¨æˆ·", cleaned_input)
        
        # æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆå¤šå±‚æ¬¡ï¼‰
        memory_context = memory_manager.retrieve_memories(cleaned_input)
        if memory_context == "æ— ç›¸å…³è®°å¿†ã€‚":
            memory_context = ""  # ä¸ä¼ é€’æ— è®°å¿†çš„ä¸Šä¸‹æ–‡
        
        # è°ƒç”¨ LLM ç”Ÿæˆå“åº”
        ai_response = call_llm(SYSTEM_PROMPT, MODEL_NAME, cleaned_input, memory_context)
        
        explain_lines = graph_memory.explain_latest()
        if explain_lines:
            memory_logger.info("[å¯è§£é‡Šé“¾] " + " | ".join(explain_lines))

        print(f"AI: {ai_response}")
        
        # åªæœ‰åœ¨éé”™è¯¯å“åº”æ—¶æ‰å¤„ç†è®°å¿†
        if ai_response != "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¡ä½äº†ã€‚":
            # æ·»åŠ AIå“åº”åˆ°çŸ­æœŸè®°å¿†
            memory_manager.add_to_short_term("AI", ai_response)
            
            # å­˜å‚¨å®Œæ•´å¯¹è¯åˆ°é•¿æœŸè®°å¿†ç³»ç»Ÿ
            memory_manager.store_memory(f"ç”¨æˆ·: {cleaned_input}\nAI: {ai_response}")
        
        # è¯­éŸ³åˆæˆ
        voice_manager.speak(ai_response)
    
    # é€€å‡ºæ—¶åœæ­¢ GPT-SoVITS è¿›ç¨‹
    if sovits_process:
        sovits_process.terminate()
        sovits_process.wait()
        print("GPT-SoVITS API æœåŠ¡å·²åœæ­¢ã€‚")

if __name__ == "__main__":
    main()