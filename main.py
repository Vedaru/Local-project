"""
Project Local - å¸¦ Avatar è™šæ‹Ÿå½¢è±¡çš„ä¸»å…¥å£æ–‡ä»¶
æ¼”ç¤ºå¦‚ä½•å°† PyQt6 GUI ä¸ AI é€»è¾‘åœ¨ä¸åŒçº¿ç¨‹ä¸­é›†æˆ
"""
import signal
import sys
import os

# å¿…é¡»åœ¨å¯¼å…¥ä»»ä½•å…¶ä»–æ¨¡å—å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¿®å¤ ctranslate2 çš„ ROCm è·¯å¾„é—®é¢˜ï¼‰
os.environ["CT2_USE_CUDA"] = "0"

import threading
import queue
import tempfile
import time
from typing import Optional

from PyQt6.QtCore import QTimer, QObject, pyqtSignal
from PyQt6.QtWidgets import QApplication

from modules.avatar import AvatarWidget, AvatarManager
from modules.avatar import LipSyncManager, ExpressionManager, Emotion
from modules.avatar.logger import log_info as avatar_log_info
from modules.memory import MemoryManager
from modules.memory.logger import get_logger as get_memory_logger
from modules.voice import VoiceManager
from modules.ear import Ear
from modules.llm import call_llm
from modules.config import REF_AUDIO, PROMPT_TEXT, SOVITS_URL, GPT_SOVITS_PATH, MODEL_NAME, SYSTEM_PROMPT
from modules.utils import clean_text, start_gpt_sovits_api, check_sovits_service
from modules.logging_config import get_logger


class AIWorkerSignals(QObject):
    """AI å·¥ä½œçº¿ç¨‹çš„ä¿¡å·å®šä¹‰ï¼Œç”¨äºä¸ä¸»çº¿ç¨‹é€šä¿¡"""
    response_ready = pyqtSignal(str)        # AI å“åº”å°±ç»ª
    lip_sync_update = pyqtSignal(float)     # å£å‹åŒæ­¥æ›´æ–°
    expression_change = pyqtSignal(object)  # è¡¨æƒ…å˜åŒ–ï¼ˆæ¥æ”¶ Emotion æšä¸¾æˆ–å­—ç¬¦ä¸²ï¼‰
    motion_play = pyqtSignal(str, int)      # æ’­æ”¾åŠ¨ä½œ
    status_update = pyqtSignal(str)         # çŠ¶æ€æ›´æ–°
    shutdown = pyqtSignal()                 # å…³é—­ä¿¡å·
    speak_request = pyqtSignal(str)         # è¯­éŸ³åˆæˆè¯·æ±‚ï¼ˆå¸¦å£å‹åŒæ­¥ï¼‰
    play_audio = pyqtSignal(str)            # æ’­æ”¾éŸ³é¢‘è¯·æ±‚ï¼ˆwav æ–‡ä»¶è·¯å¾„ï¼‰
    ear_recognized = pyqtSignal(str)        # éº¦å…‹é£è¯†åˆ«ç»“æœï¼ˆæ¥è‡ª Ear æ¨¡å—ï¼‰


class EarWorker(threading.Thread):
    """
    Ear å·¥ä½œçº¿ç¨‹ï¼šåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œéº¦å…‹é£ç›‘å¬
    è¯†åˆ«åˆ°æ–‡æœ¬åé€šè¿‡é˜Ÿåˆ—å‘é€ç»™ AIWorker å¤„ç†
    """
    
    def __init__(self, input_queue: queue.Queue, model_size: str = "base"):
        super().__init__(daemon=True)
        self.input_queue = input_queue
        self.model_size = model_size
        self.ear = None
        self._running = True
    
    def run(self):
        """çº¿ç¨‹ä¸»å¾ªç¯"""
        logger = get_logger('EarWorker')
        try:
            logger.info(f"[Ear] åˆå§‹åŒ–å¬è§‰æ¨¡å—ï¼Œæ¨¡å‹å¤§å°: {self.model_size}")
            self.ear = Ear(model_size=self.model_size)
            
            def on_text_recognized(text: str):
                """å½“è¯†åˆ«åˆ°æ–‡æœ¬æ—¶ï¼Œå‘é€åˆ° AIWorker çš„è¾“å…¥é˜Ÿåˆ—"""
                if self._running and text.strip():
                    logger.info(f"[Ear] è¯†åˆ«ç»“æœ: {text}")
                    self.input_queue.put(text)
            
            # å¼€å§‹é˜»å¡ç›‘å¬éº¦å…‹é£
            logger.info("[Ear] å¼€å§‹ç›‘å¬éº¦å…‹é£...")
            self.ear.listen(callback=on_text_recognized)
            
        except Exception as e:
            logger.error(f"[Ear] é”™è¯¯: {e}", exc_info=True)
        finally:
            if self.ear:
                self.ear.close()
            logger.info("[Ear] å¬è§‰æ¨¡å—å·²å…³é—­")
    
    def stop(self):
        """åœæ­¢ç›‘å¬"""
        self._running = False
        if self.ear:
            self.ear.stop()


class AIWorker(threading.Thread):
    """
    AI å·¥ä½œçº¿ç¨‹
    å¤„ç†ç”¨æˆ·è¾“å…¥ã€è°ƒç”¨ LLMã€è¯­éŸ³åˆæˆç­‰ AI é€»è¾‘
    é€šè¿‡ä¿¡å·ä¸ä¸»çº¿ç¨‹çš„ GUI é€šä¿¡
    """
    
    def __init__(
        self,
        signals: AIWorkerSignals,
        input_queue: queue.Queue,
        memory_manager: MemoryManager,
        voice_manager: VoiceManager
    ):
        super().__init__(daemon=True)
        self.signals = signals
        self.input_queue = input_queue
        self.memory_manager = memory_manager
        self.voice_manager = voice_manager
        self._running = True
    
    def run(self):
        """çº¿ç¨‹ä¸»å¾ªç¯"""
        logger = get_logger('AIWorker')
        while self._running:
            try:
                # ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼ˆå¸¦è¶…æ—¶ï¼Œä¾¿äºæ£€æŸ¥ _running çŠ¶æ€ï¼‰
                try:
                    user_input = self.input_queue.get(timeout=0.5)
                except queue.Empty:
                    continue
                
                if user_input is None:  # é€€å‡ºä¿¡å·
                    break
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['exit', 'quit']:
                    self.signals.shutdown.emit()
                    break
                
                if user_input.lower() == 'status':
                    stats = self.memory_manager.get_memory_stats()
                    status_msg = (
                        f"ğŸ“Š è®°å¿†ç³»ç»ŸçŠ¶æ€:\n"
                        f"  â”œâ”€ çŸ­æœŸè®°å¿†: {stats['short_term']}/{stats['short_term_capacity']} è½®\n"
                        f"  â”œâ”€ å·¥ä½œè®°å¿†: {stats['working_memory']} æ¡\n"
                        f"  â”œâ”€ é•¿æœŸè®°å¿†: {stats['long_term']} æ¡\n"
                        f"  â”œâ”€ æƒ…æ„Ÿè®°å¿†: {stats['emotional']} æ¡\n"
                        f"  â””â”€ å½“å‰æƒ…æ„Ÿ: {stats['current_emotion']}"
                    )
                    self.signals.status_update.emit(status_msg)
                    continue
                
                # æ¸…ç†è¾“å…¥æ–‡æœ¬
                cleaned_input = clean_text(user_input)
                
                # è·³è¿‡ç©ºè¾“å…¥
                if not cleaned_input.strip():
                    continue
                
                # æ·»åŠ åˆ°çŸ­æœŸè®°å¿†
                self.memory_manager.add_to_short_term("ç”¨æˆ·", cleaned_input)
                
                # æ£€ç´¢ç›¸å…³è®°å¿†
                memory_context = self.memory_manager.retrieve_memories(cleaned_input)
                if memory_context == "æ— ç›¸å…³è®°å¿†ã€‚":
                    memory_context = ""
                
                # å¼€å§‹æ€è€ƒæ—¶å¯ä»¥åˆ‡æ¢è¡¨æƒ…
                self.signals.expression_change.emit(Emotion.THINKING)
                
                # è°ƒç”¨ LLM ç”Ÿæˆå“åº”
                ai_response = call_llm(SYSTEM_PROMPT, MODEL_NAME, cleaned_input, memory_context)
                
                # æ ¹æ®å“åº”å†…å®¹è‡ªåŠ¨åˆ‡æ¢è¡¨æƒ…
                self.signals.expression_change.emit(ai_response)  # å‘é€æ–‡æœ¬ï¼Œè®©ä¸»çº¿ç¨‹åˆ†ææƒ…æ„Ÿ
                
                # å‘é€å“åº”åˆ°ä¸»çº¿ç¨‹
                self.signals.response_ready.emit(ai_response)
                
                # å¤„ç†è®°å¿†
                if ai_response != "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¡ä½äº†ã€‚":
                    self.memory_manager.add_to_short_term("AI", ai_response)
                    self.memory_manager.store_memory(f"ç”¨æˆ·: {cleaned_input}\nAI: {ai_response}")
                
                # è¯­éŸ³åˆæˆï¼ˆè¯·æ±‚ä¸»çº¿ç¨‹è¿›è¡Œå£å‹åŒæ­¥ï¼‰
                self.signals.speak_request.emit(ai_response)
                
            except Exception as e:
                logger.error(f"Error: {e}", exc_info=True)
    
    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self._running = False


class MainApplication:
    """
    ä¸»åº”ç”¨ç¨‹åºç±»
    ç®¡ç† PyQt åº”ç”¨ã€Avatar çª—å£å’Œ AI å·¥ä½œçº¿ç¨‹
    """
    
    def __init__(self):
        self.app: Optional[QApplication] = None
        self.avatar: Optional[AvatarWidget] = None
        self.ai_worker: Optional[AIWorker] = None
        self.ear_worker: Optional[EarWorker] = None  # æ–°å¢ï¼šEar å·¥ä½œçº¿ç¨‹
        self.input_queue: queue.Queue = queue.Queue()
        self.signals: Optional[AIWorkerSignals] = None
        
        self.memory_manager: Optional[MemoryManager] = None
        self.voice_manager: Optional[VoiceManager] = None
        self.sovits_process = None
        
        # å£å‹åŒæ­¥å’Œè¡¨æƒ…ç®¡ç†å™¨
        self.lip_sync_manager: Optional[LipSyncManager] = None
        self.expression_manager: Optional[ExpressionManager] = None
        
        # ç”¨äºæ§åˆ¶è¾“å…¥æç¤ºç¬¦çš„äº‹ä»¶
        self.can_input = threading.Event()
        self.can_input.set()  # åˆå§‹åŒ–ä¸ºå¯è¾“å…¥çŠ¶æ€
    
    def setup(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        logger = get_logger('MainApplication')
        
        # åˆ›å»º PyQt åº”ç”¨ï¼ˆå¿…é¡»æœ€å…ˆåˆ›å»ºï¼‰
        self.app = QApplication(sys.argv)
        
        # åˆ›å»ºä¿¡å·å¯¹è±¡
        self.signals = AIWorkerSignals()
        self._connect_signals()
        
        # å¯åŠ¨ GPT-SoVITS æœåŠ¡
        self.sovits_process = start_gpt_sovits_api(GPT_SOVITS_PATH)
        if self.sovits_process is None:
            logger.warning("GPT-SoVITS API æœåŠ¡å¯åŠ¨å¤±è´¥ã€‚")
        
        # åˆå§‹åŒ–æ¨¡å—
        self.memory_manager = MemoryManager()
        self.voice_manager = VoiceManager(
            sovits_url=SOVITS_URL,
            ref_audio=REF_AUDIO,
            prompt_text=PROMPT_TEXT,
        )
        
        # æ¸…ç†æ—§è®°å¿†
        self.memory_manager.cleanup_old_memories()
        
        # åˆ›å»º Avatar çª—å£
        self.avatar = AvatarWidget(
            width=400,
            height=600,
            x=100,
            y=100
        )
        
        # åˆå§‹åŒ–å£å‹åŒæ­¥ç®¡ç†å™¨ï¼ˆé€šè¿‡ä¿¡å·æ›´æ–°ï¼Œä¿è¯çº¿ç¨‹å®‰å…¨ï¼‰
        self.lip_sync_manager = LipSyncManager(
            update_callback=lambda v: self.signals.lip_sync_update.emit(v)
        )
        
        # åˆå§‹åŒ–è¡¨æƒ…ç®¡ç†å™¨
        self.expression_manager = ExpressionManager(
            expression_callback=self._change_expression,
            motion_callback=self._play_motion
        )
        
        # å¯åŠ¨ AI å·¥ä½œçº¿ç¨‹
        self.ai_worker = AIWorker(
            signals=self.signals,
            input_queue=self.input_queue,
            memory_manager=self.memory_manager,
            voice_manager=self.voice_manager
        )
    
    def _connect_signals(self):
        """è¿æ¥ä¿¡å·ä¸æ§½"""
        self.signals.response_ready.connect(self._on_response_ready)
        self.signals.lip_sync_update.connect(self._on_lip_sync_update)
        self.signals.expression_change.connect(self._on_expression_change)
        self.signals.motion_play.connect(self._on_motion_play)
        self.signals.status_update.connect(self._on_status_update)
        self.signals.shutdown.connect(self._on_shutdown)
        self.signals.speak_request.connect(self._on_speak_request)
        self.signals.play_audio.connect(self._on_play_audio)
        self.signals.ear_recognized.connect(self._on_ear_recognized)
    
    def _change_expression(self, expression_index: int):
        """è¡¨æƒ…åˆ‡æ¢å›è°ƒ - è¢« ExpressionManager è°ƒç”¨"""
        if self.avatar:
            self.avatar.change_expression(expression_index)
    
    def _play_motion(self, group: str, index: int):
        """æ’­æ”¾åŠ¨ä½œå›è°ƒ - è¢« ExpressionManager è°ƒç”¨"""
        if self.avatar:
            self.avatar.play_motion(group, index)
    
    def _on_response_ready(self, response: str):
        """å¤„ç† AI å“åº”"""
        logger = get_logger('MainApplication')
        logger.info(f"AI: {response}")
        # å“åº”å®Œæˆï¼Œå…è®¸ä¸‹ä¸€æ¬¡è¾“å…¥
        self.can_input.set()
    
    def _on_lip_sync_update(self, value: float):
        """æ›´æ–°å£å‹ï¼ˆç›´æ¥ä¿¡å·è°ƒç”¨ï¼‰"""
        if self.avatar:
            self.avatar.update_lip_sync(value)
    
    def _on_expression_change(self, expression):
        """åˆ‡æ¢è¡¨æƒ… - æ¥æ”¶ Emotion æšä¸¾æˆ–æ–‡æœ¬å­—ç¬¦ä¸²"""
        if self.expression_manager:
            if isinstance(expression, Emotion):
                # ç›´æ¥è®¾ç½®æƒ…æ„Ÿ
                self.expression_manager.set_emotion(expression)
            elif isinstance(expression, str):
                # åˆ†ææ–‡æœ¬å†…å®¹çš„æƒ…æ„Ÿ
                self.expression_manager.set_expression_from_text(expression)
    
    def _on_motion_play(self, group: str, index: int):
        """æ’­æ”¾åŠ¨ä½œ"""
        if self.avatar:
            self.avatar.play_motion(group, index)
    
    def _on_speak_request(self, text: str):
        """å¤„ç†è¯­éŸ³åˆæˆè¯·æ±‚ - æµè§ˆå™¨å†…éŸ³é¢‘æ’­æ”¾å’Œå£å‹åŒæ­¥ï¼ˆ100%å®Œç¾åŒæ­¥ï¼‰"""
        logger = get_logger('MainApplication')
        logger.debug(f"[TTS] æ”¶åˆ°è¯­éŸ³è¯·æ±‚: {text[:50]}...")
        
        if self.voice_manager and self.avatar:
            try:
                # ç”Ÿæˆä¸´æ—¶ wav æ–‡ä»¶è·¯å¾„
                wav_path = os.path.join(
                    os.path.dirname(__file__), 
                    'data', 'temp', 
                    f'tts_{int(time.time() * 1000)}.wav'
                )
                os.makedirs(os.path.dirname(wav_path), exist_ok=True)
                logger.debug(f"[TTS] wav ä¿å­˜è·¯å¾„: {wav_path}")
                
                # åœ¨å­çº¿ç¨‹ä¸­æ‰§è¡Œ TTSï¼ˆé¿å…é˜»å¡ä¸»çº¿ç¨‹ï¼‰
                def speak_with_browser():
                    try:
                        logger.debug("[TTS] å¼€å§‹åˆæˆè¯­éŸ³...")
                        
                        # 1. åˆæˆè¯­éŸ³å¹¶ä¿å­˜åˆ°æœ¬åœ°
                        if not self.voice_manager.speak_and_save(text, wav_path):
                            logger.warning("[TTS] è¯­éŸ³åˆæˆå¤±è´¥")
                            return
                        
                        logger.debug(f"[TTS] è¯­éŸ³åˆæˆæˆåŠŸ, æ–‡ä»¶å­˜åœ¨: {os.path.exists(wav_path)}")
                        
                        # 2. é€šè¿‡ä¿¡å·è®©ä¸»çº¿ç¨‹æ’­æ”¾éŸ³é¢‘
                        logger.debug("[TTS] å‘é€ play_audio ä¿¡å·...")
                        self.signals.play_audio.emit(wav_path)
                        
                        # 3. ç­‰å¾…éŸ³é¢‘æ—¶é•¿åæ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        import wave
                        try:
                            with wave.open(wav_path, 'rb') as wf:
                                frames = wf.getnframes()
                                rate = wf.getframerate()
                                duration = frames / float(rate)
                            
                            logger.debug(f"[TTS] éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")
                                
                            # ç­‰å¾…æ’­æ”¾å®Œæˆåæ¸…ç†
                            time.sleep(duration + 0.5)
                            try:
                                os.remove(wav_path)
                                logger.debug("[TTS] ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
                            except:
                                pass
                        except Exception as e:
                            logger.warning(f"[TTS] è¯»å– wav é”™è¯¯: {e}")
                            
                    except Exception as e:
                        logger.error(f"[TTS] é”™è¯¯: {e}", exc_info=True)
                
                # å¯åŠ¨å­çº¿ç¨‹æ‰§è¡Œ
                threading.Thread(target=speak_with_browser, daemon=True).start()
                
            except Exception as e:
                logger.error(f"[TTS] é”™è¯¯: {e}", exc_info=True)
        else:
            logger.warning(f"[TTS] voice_manager={self.voice_manager}, avatar={self.avatar}")
    
    def _on_play_audio(self, wav_path: str):
        """åœ¨ä¸»çº¿ç¨‹ä¸­æ’­æ”¾éŸ³é¢‘ï¼ˆç”±ä¿¡å·è§¦å‘ï¼‰"""
        logger = get_logger('MainApplication')
        logger.debug(f"[TTS] ä¸»çº¿ç¨‹æ”¶åˆ°æ’­æ”¾è¯·æ±‚: {wav_path}")
        if self.avatar:
            self.avatar.play_audio(wav_path)
    
    def _on_status_update(self, status: str):
        """æ˜¾ç¤ºçŠ¶æ€"""
        print(status)
    
    def _on_ear_recognized(self, text: str):
        """å¤„ç† Ear æ¨¡å—è¯†åˆ«çš„æ–‡æœ¬"""
        logger = get_logger('MainApplication')
        logger.info(f"[Ear è¯†åˆ«] {text}")
        # Ear å·²å°†æ–‡æœ¬æ”¾å…¥ input_queueï¼ŒAIWorker ä¼šè‡ªåŠ¨å¤„ç†
    
    def _on_shutdown(self):
        """å¤„ç†å…³é—­ä¿¡å·"""
        self.cleanup()
        self.app.quit()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger = get_logger('MainApplication')
        
        # åœæ­¢å£å‹åŒæ­¥
        if self.lip_sync_manager:
            self.lip_sync_manager.stop()
        
        # åœæ­¢ Ear å·¥ä½œçº¿ç¨‹
        if self.ear_worker:
            self.ear_worker.stop()
        
        # åœæ­¢ AI å·¥ä½œçº¿ç¨‹
        if self.ai_worker:
            self.ai_worker.stop()
            self.input_queue.put(None)  # å‘é€é€€å‡ºä¿¡å·
        
        # ä¿å­˜è®°å¿†
        if self.memory_manager:
            self.memory_manager.summarize_day()
            self.memory_manager.close()
        
        # åœæ­¢è¯­éŸ³æœåŠ¡
        if self.sovits_process:
            self.sovits_process.terminate()
            self.sovits_process.wait()
            logger.info("GPT-SoVITS API æœåŠ¡å·²åœæ­¢ã€‚")
    
    def run(self):
        """è¿è¡Œåº”ç”¨ç¨‹åº"""
        logger = get_logger('MainApplication')
        
        # æ˜¾ç¤º Avatar çª—å£
        self.avatar.show()
        
        # å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼ˆç­‰å¾…é¡µé¢åŠ è½½å®Œæˆï¼‰
        QTimer.singleShot(1500, self._load_default_model)
        
        # å¯åŠ¨ Ear å·¥ä½œçº¿ç¨‹ï¼ˆéº¦å…‹é£ç›‘å¬ï¼‰
        logger.info("æ­£åœ¨å¯åŠ¨ Ear å¬è§‰æ¨¡å—...")
        self.ear_worker = EarWorker(self.input_queue, model_size="base")
        self.ear_worker.start()
        
        # å¯åŠ¨ AI å·¥ä½œçº¿ç¨‹
        self.ai_worker.start()
        
        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        stats = self.memory_manager.get_memory_stats()
        logger.info("=" * 60)
        logger.info("Project Local å·²å¯åŠ¨ï¼ˆå¸¦ Avatar å’Œ Ear å¬è§‰æ¨¡å—ï¼‰ã€‚")
        logger.info(f"è®°å¿†çŠ¶æ€: çŸ­æœŸ({stats['short_term']}/{stats['short_term_capacity']}) | "
                   f"é•¿æœŸ({stats['long_term']}) | æƒ…æ„Ÿ({stats['emotional']})")
        logger.info("ğŸ“£ ç°åœ¨å¯ä»¥ç›´æ¥å¯¹éº¦å…‹é£è¯´è¯ï¼")
        logger.info("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºï¼Œè¾“å…¥ 'status' æŸ¥çœ‹è®°å¿†çŠ¶æ€ã€‚")
        logger.info("=" * 60)
        
        # å¯åŠ¨æ§åˆ¶å°è¾“å…¥çº¿ç¨‹ï¼ˆåœ¨å¯åŠ¨ä¿¡æ¯ä¹‹åï¼‰
        console_thread = threading.Thread(target=self._console_input_loop, daemon=True)
        console_thread.start()
        
        # è¿è¡Œ Qt äº‹ä»¶å¾ªç¯ï¼ˆé˜»å¡ï¼‰
        return self.app.exec()
    
    def _load_default_model(self):
        """åŠ è½½é»˜è®¤æ¨¡å‹"""
        # ç¤ºä¾‹ï¼šå¦‚æœ models ç›®å½•ä¸‹æœ‰æ¨¡å‹ï¼Œè‡ªåŠ¨åŠ è½½ç¬¬ä¸€ä¸ª
        from pathlib import Path
        models_dir = Path(__file__).parent / "assets" / "web" / "models"
        if models_dir.exists():
            for model_file in models_dir.rglob("*.model3.json"):
                avatar_log_info(f"Found model: {model_file}")
                self.avatar.load_model(str(model_file))
                break
            else:
                for model_file in models_dir.rglob("*.model.json"):
                    avatar_log_info(f"Found model: {model_file}")
                    self.avatar.load_model(str(model_file))
                    break
                else:
                    avatar_log_info("No model found in models directory")
    
    def _console_input_loop(self):
        """æ§åˆ¶å°è¾“å…¥å¾ªç¯ï¼ˆåœ¨å­çº¿ç¨‹è¿è¡Œï¼‰"""
        import time
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿å¯åŠ¨ä¿¡æ¯æ‰“å°å®Œæˆ
        time.sleep(0.5)
        
        while True:
            try:
                # ç­‰å¾…å…è®¸è¾“å…¥
                self.can_input.wait()
                
                user_input = input("ä½ : ")
                
                # è®¾ç½®ä¸ºä¸å¯è¾“å…¥çŠ¶æ€ï¼Œç›´åˆ° AI å“åº”å®Œæˆ
                if user_input.strip():
                    self.can_input.clear()
                
                self.input_queue.put(user_input)
                
                if user_input.lower() in ['exit', 'quit']:
                    break
            except EOFError:
                break
            except Exception as e:
                pass  # å¿½ç•¥è¾“å…¥é”™è¯¯


def signal_handler(sig, frame):
    """å¤„ç† Ctrl+C ä¿¡å·"""
    print("\næ­£åœ¨é€€å‡º...")
    sys.exit(0)


def main():
    """ä¸»å…¥å£"""
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger = get_logger('ProjectLocal')
    logger.info("å¯åŠ¨ Project Local...")
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    
    # åˆ›å»ºå¹¶è¿è¡Œåº”ç”¨
    app = MainApplication()
    app.setup()
    
    try:
        sys.exit(app.run())
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")
        app.cleanup()
        sys.exit(0)


if __name__ == "__main__":
    import sys
    # æä¾›ä¸€ä¸ªå¯é€‰çš„å‘½ä»¤è¡Œå‚æ•°: --ear-demo ï¼Œç”¨äºå¿«é€Ÿæœ¬åœ°æµ‹è¯• modules/ear.py çš„å¬è§‰åŠŸèƒ½
    if "--ear-demo" in sys.argv:
        print("[main] å¯åŠ¨ Ear æ¨¡å—æ¼”ç¤º (--ear-demo)ã€‚æŒ‰ Ctrl+C é€€å‡ºã€‚")
        from modules.ear import Ear
        ear = Ear(model_size="base")
        try:
            ear.listen(callback=lambda txt: print("[EAR DEMO] è¯†åˆ«:", txt))
        finally:
            ear.close()
            sys.exit(0)

    main()
